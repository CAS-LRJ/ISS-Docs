---
title: Welcome
layout: home
nav_order: 0
---

# ISS

Intelligent Self-driving System (ISS) is a modular framework written in Python and C++ with the aim to build an extensible workspace tailored to research. This framework will contain both traditional and deep learning algorithms for self-driving related tasks such as perception, localization, mapping, prediction, planning, and control. The modular design with minimal dependency on external libraries can provide a transparent and clean workspace for researchers to evaluate algorithms for autonomous driving systems.

![ISS Architecture](assets/ISS_Framework.png){: .center-image }

*ISS Architecture*
{: .text-center}

## Simulator Demos
At present, the ISS framework has the capability to deploy and test algorithms using data generated by a simulator. Upon integrating sensor data from the CARLA simulator into our framework, we can evaluate a range of algorithms. Additionally, corresponding control algorithms can be employed to maneuver the simulated vehicles. Here are some demonstrations.

<video width="640" height="360" controls>
  <source src="assets/following_1.mp4" type="video/mp4">
</video>
{: .center-image }

A real-time demonstration of the PointPillar 3D detection algorithm within the Carla simulator
{: .text-center}

<video width="640" height="360" controls>
  <source src="assets/local_planning.mp4" type="video/mp4">
</video>
{: .center-image }

A demo showing the local behavior planning 
{: .text-center}


## Minicar Demos
In addition to simulation results, if the sensor data from a real minicar is transmitted back to ISS via ROS, the ISS framework can leverage the sensor data to accomplish a variety of tasks and exert control over the physical minicar. We present below three videos showing the interaction of ISS with real minicars.


<video width="640" height="360" controls>
  <source src="assets/nav_indoor_small.mp4" type="video/mp4">
</video>
{: .center-image }

<video width="640" height="360" controls>
  <source src="assets/nav_outdoor_small.mp4" type="video/mp4">
</video>
{: .center-image }

Two demos featuring physical minicars navigating indoor and outdoor environments, respectively
{: .text-center}


<video width="640" height="360" controls>
  <source src="assets/localization_aloam_small.mp4" type="video/mp4">
</video>
{: .center-image }

A demo showcasing the A-LOAM SLAM algorithm using data from physical minicars
{: .text-center}

<!-- ## Our Works

Currently, we have leveraged components of the ISS for various tasks, including scene construction, autonomous driving safety verification, and adversarial attacks on perception models.

<video width="640" height="360" controls>
  <source src="assets/LeftCutInSmall.mp4" type="video/mp4">
</video>
{: .center-image }
A simple left cut-in scenario built
{: .text-center} -->
